**README**

# Blazor.NET 8 and FastAPI Chat Comparison Application

## Overview

This application is a chat comparison tool developed using Blazor.NET 8 for the front-end and FastAPI for the back-end. The purpose of this tool is to compare responses generated by local and remote models (such as Hugging Face models or LlamaAPI) based on user queries.

## Features

1. **User Interface**: The front-end is built using Blazor.NET 8, providing a responsive and interactive user interface. It includes:
   - Two dropdowns for selecting local and remote models.
   - Text area for entering queries.
   - Display areas for showing chat history of local and remote responses.
   - "Save history" button to save the chat history to a file.

2. **Communication with FastAPI**: The application communicates with a FastAPI backend hosted at `http://fastapi:8000` when using `docker-compose up --build` or `localhost` whith same port when testing without docker. The backend handles requests for model comparison and fetching available models.

3. **Model Comparison**: Upon entering a query and pressing Enter, the application sends the query, selected local, and remote models to the FastAPI backend. The backend uses Hugging Face or LlamaAPI to generate responses for local and remote models and returns the results.

4. **Dynamic Model Loading**: The application dynamically loads available local and remote models from the FastAPI backend during initialization.

5. **Saving Chat History**: Users can save the chat history (both local and remote) to a text file by clicking the "Save history" button.

## Setup and Run Instructions

### Blazor.NET Front-end

1. Ensure you have the appropriate .NET SDK installed (compatible with Blazor.NET 8).
2. Navigate to the Blazor.NET project directory in the terminal.
3. Run the application using the command: `dotnet run`.

### FastAPI Back-end

1. Ensure you have Python installed on your system.
2. add .env in BackEnd with those two keys `lApiToken=your llamaapi token` and `header=inference api auth key`
3. Install dependencies using: `pip install -r requirements.txt`.
4. Run the FastAPI application using: `uvicorn main:app --reload`.

## Important Note

- This application assumes the existence of a FastAPI server with the specified endpoints for model comparison and model retrieval. Make sure the FastAPI server is running and accessible.

Feel free to explore and customize the application for your specific use case! If you encounter any issues, refer to the documentation of Blazor.NET and FastAPI for troubleshooting.

Happy coding! ðŸš€
